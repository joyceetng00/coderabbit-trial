# LabelBench Repository

This repository contains the LabelBench application - a lightweight Python-based web application for annotating LLM responses to build golden evaluation datasets.

## ğŸ“ Repository Structure

```
coderabbit-trial/
â”œâ”€â”€ labelbench/              # Main application directory
â”‚   â”œâ”€â”€ app.py              # Streamlit entry point
â”‚   â”œâ”€â”€ models/             # Pydantic data models
â”‚   â”œâ”€â”€ storage/            # Database & import/export utilities
â”‚   â”œâ”€â”€ ui/                 # Streamlit UI pages
â”‚   â”œâ”€â”€ tests/              # Unit tests
â”‚   â”œâ”€â”€ data/               # Example datasets
â”‚   â”œâ”€â”€ pyproject.toml      # Project dependencies
â”‚   â””â”€â”€ README.md           # Application documentation
â”‚
â”œâ”€â”€ context_files/          # Development & specification documents
â”‚   â”œâ”€â”€ SPEC_REVIEW.md      # Technical review of the specification
â”‚   â”œâ”€â”€ SPEC_UPDATES.md     # Changes made to the original spec
â”‚   â”œâ”€â”€ TESTING_CHECKLIST.md # Testing requirements & setup guide
â”‚   â””â”€â”€ UI_CHANGES.md       # UI bug fixes & improvements
â”‚
â”œâ”€â”€ labelbench_spec.md      # Complete technical specification
â””â”€â”€ README.md               # This file
```

## ğŸš€ Quick Start

### For Users
Navigate to the `labelbench/` directory and follow the instructions in `labelbench/README.md`:

```bash
cd labelbench
uv sync --extra dev
uv run streamlit run app.py
```

### For Developers
See the documentation files in `context_files/` for development context.

## ğŸ“š Documentation Navigation

### Application Documentation
- **`labelbench/README.md`** - Complete application guide with:
  - Quick start instructions
  - Architecture diagrams
  - Usage examples
  - Feature overview

### Development Context
All development-related documents are in `context_files/`:

- **`SPEC_REVIEW.md`** - Technical review of the specification:
  - Architecture assessment
  - Critical issues identified
  - Technology stack review
  - Recommendations for improvements

- **`SPEC_UPDATES.md`** - Changes made to the original specification:
  - Package manager switch (uv)
  - Time reference removals
  - Critical bug fixes
  - Implementation completion notes

- **`TESTING_CHECKLIST.md`** - Testing requirements:
  - What you need to prepare separately
  - Environment setup
  - Testing workflow
  - Common issues & solutions

- **`UI_CHANGES.md`** - UI improvements and bug fixes:
  - Issues identified
  - Proposed fixes
  - Implementation details
  - Testing checklist

### Technical Specification
- **`labelbench_spec.md`** - Complete technical specification:
  - Full implementation guide
  - Phase-by-phase instructions
  - Code examples
  - PR structure

## ğŸ—‚ï¸ Directory Details

### `labelbench/` - Main Application
The complete LabelBench application with all components:

- **`app.py`** - Main Streamlit entry point with navigation
- **`models/`** - Pydantic data models (Sample, Annotation)
- **`storage/`** - Database layer and import/export utilities
- **`ui/`** - Streamlit UI pages (Import, Annotate, Analysis)
- **`tests/`** - Unit tests for models and database
- **`data/`** - Example datasets for testing
- **`pyproject.toml`** - Project dependencies and configuration

### `context_files/` - Development Documentation
Supporting documents for understanding the development process:

- Technical reviews and assessments
- Specification updates and changes
- Testing guides and checklists
- UI improvement documentation

## ğŸ” Finding What You Need

### I want to...
- **Run the application** â†’ See `labelbench/README.md`
- **Understand the architecture** â†’ See `labelbench/README.md` (architecture diagram)
- **Review technical decisions** â†’ See `context_files/SPEC_REVIEW.md`
- **See what changed from spec** â†’ See `context_files/SPEC_UPDATES.md`
- **Set up for testing** â†’ See `context_files/TESTING_CHECKLIST.md`
- **Understand UI fixes** â†’ See `context_files/UI_CHANGES.md`
- **Read the full spec** â†’ See `labelbench_spec.md`
- **Find code examples** â†’ See `labelbench_spec.md` or browse `labelbench/`

## ğŸ› ï¸ Development Workflow

1. **Read the spec** â†’ `labelbench_spec.md`
2. **Review technical assessment** â†’ `context_files/SPEC_REVIEW.md`
3. **Check updates** â†’ `context_files/SPEC_UPDATES.md`
4. **Set up environment** â†’ `context_files/TESTING_CHECKLIST.md`
5. **Review UI changes** â†’ `context_files/UI_CHANGES.md`
6. **Run the app** â†’ `labelbench/README.md`

## ğŸ“ Key Features

- âœ… Import prompt-response pairs from CSV/JSON
- âœ… Binary Accept/Reject annotation with structured feedback
- âœ… Interactive error analysis dashboard
- âœ… Metadata breakdowns and filtering
- âœ… Local SQLite storage
- âœ… Export rejected samples for downstream evaluation

## ğŸ”— Quick Links

- [Application README](labelbench/README.md)
- [Technical Specification](labelbench_spec.md)
- [Technical Review](context_files/SPEC_REVIEW.md)
- [Spec Updates](context_files/SPEC_UPDATES.md)
- [Testing Guide](context_files/TESTING_CHECKLIST.md)
- [UI Changes](context_files/UI_CHANGES.md)

## ğŸ“„ License

MIT

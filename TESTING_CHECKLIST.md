# LabelBench Testing Checklist

## What You Need to Prepare Separately

### âœ… 1. Test Dataset (CSV or JSON)

You mentioned you already know about this, but here's the format needed:

**CSV Format:**
```csv
id,prompt,response,model,task_type
sample_1,"What's your return policy?","You can return items within 30 days...",gpt-4,customer_support
sample_2,"Do you ship to Canada?","Yes, we offer free shipping...",gpt-3.5,customer_support
```

**Required columns:** `id`, `prompt`, `response`  
**Optional columns:** Any additional columns become metadata

**JSON Format:**
```json
{
  "samples": [
    {
      "id": "sample_1",
      "prompt": "What's your return policy?",
      "response": "You can return items within 30 days...",
      "metadata": {
        "model": "gpt-4",
        "task_type": "customer_support"
      }
    }
  ]
}
```

**Recommendations:**
- Start with 20-50 samples for initial testing
- Include diverse error types (hallucinations, incomplete responses, wrong format, etc.)
- Mix of acceptable and problematic responses
- Varied metadata values (different models, task types) to test filtering

---

### âœ… 2. Environment Setup

**Python 3.10+ installed:**
```bash
python --version  # Should be 3.10 or higher
```

**uv package manager installed:**
```bash
# Install uv if not already installed
curl -LsSf https://astral.sh/uv/install.sh | sh
# or
pip install uv
```

**Verify installation:**
```bash
uv --version
```

---

### âœ… 3. Install Dependencies

From the `labelbench` directory:
```bash
cd labelbench
uv sync --extra dev  # Installs all dependencies including dev tools
```

This will:
- Create virtual environment automatically
- Install Streamlit, Pandas, Plotly, Pydantic
- Install pytest for testing

---

### âœ… 4. Run Unit Tests First

Before running the app, verify core components work:
```bash
cd labelbench
uv run pytest tests/ -v
```

**Expected:** All tests should pass. If they fail, fix those issues before proceeding.

---

### âœ… 5. Test Import Functionality

Before using the UI, verify import works:
```python
# Quick test script (test_import.py)
from storage.import_export import import_csv

try:
    samples = import_csv("data/example_samples.csv")
    print(f"âœ… Successfully imported {len(samples)} samples")
    print(f"First sample: {samples[0].id}")
except Exception as e:
    print(f"âŒ Import failed: {e}")
```

Run with:
```bash
uv run python test_import.py
```

---

### âœ… 6. Verify Database Creation

When you first run the app, it should create `labelbench.db` automatically. Check:
```bash
ls -lh labelbench.db  # Should exist after first run
```

---

### âœ… 7. Streamlit Configuration (Optional)

Create `.streamlit/config.toml` if you want to customize:
```toml
[server]
port = 8501
maxUploadSize = 200  # MB, adjust if needed for large files
```

---

## What Gets Created Automatically

âœ… Database file (`labelbench.db`) - Created on first run  
âœ… SQLite tables and indexes - Created automatically  
âœ… Session state - Managed by Streamlit  

---

## Quick Start Testing Workflow

1. **Prepare your dataset** â†’ Save as `data/test_samples.csv`
2. **Install dependencies** â†’ `uv sync --extra dev`
3. **Run tests** â†’ `uv run pytest tests/ -v`
4. **Start app** â†’ `uv run streamlit run app.py`
5. **Test import** â†’ Upload your CSV in the Import page
6. **Test annotation** â†’ Annotate a few samples
7. **Test analysis** â†’ Check the Error Analysis dashboard
8. **Test export** â†’ Export rejected samples

---

## Common Issues & Solutions

**Issue: "Module not found"**
- Solution: Run `uv sync` to install dependencies
- Make sure you're in the `labelbench` directory

**Issue: "Database locked"**
- Solution: Close any other instances of the app
- Delete `labelbench.db` and restart (will recreate it)

**Issue: "Import validation errors"**
- Check CSV has required columns: `id`, `prompt`, `response`
- Ensure IDs contain only letters, numbers, underscores, hyphens
- Check for empty rows or missing data

**Issue: "Port already in use"**
- Solution: Kill existing Streamlit process or change port in config

---

## Next Steps After Initial Testing

1. âœ… Import works correctly
2. âœ… Annotation saves to database
3. âœ… Error Analysis dashboard displays
4. âœ… Export functionality works
5. âœ… Navigation (Previous/Next/Jump) works
6. âœ… Bounds checking prevents crashes

---

## Files You Should Have

```
labelbench/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sample.py
â”‚   â””â”€â”€ annotation.py
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database.py
â”‚   â””â”€â”€ import_export.py
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ import_page.py
â”‚   â”œâ”€â”€ annotate_page.py
â”‚   â””â”€â”€ analysis_page.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_database.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ example_samples.csv  â† YOUR DATASET GOES HERE
â”œâ”€â”€ app.py
â”œâ”€â”€ pyproject.toml
â””â”€â”€ .gitignore
```

---

**You're ready to test once you have:**
- âœ… Test dataset (CSV or JSON)
- âœ… Python 3.10+ installed
- âœ… uv installed
- âœ… Dependencies installed (`uv sync`)

Everything else will be created automatically! ğŸš€

